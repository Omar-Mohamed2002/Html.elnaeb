<html>
<body>
<h1>History of artificial intelligence</h1>

<h2><links:></h2.>
<ul>
    <li><a href="index.html">main page</a</li>
    <li><a href="meaning of artificial intelligence.html">meaning of artificial intelligence </a></li>
    <li><a href="Artificial intelligence applications.html">Artificial intelligence applications</a></li>
    <li><a href="History of artificial intelligence.html">History of artificial intelligence</a></li>
    <li><a href="Deep learning vs. machine learning.html">Deep learning vs. machine learning</a></li>

    <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTEQXpMCxjttiLC2-uT60iXguEpzs3dD8exDQ&usqp=CAU" alt="photo">
   <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQBb-bGtvz3yhA6gy0GzT6E1djaWSyqlwEu1Q&usqp=CAU" alt="photo">

<h3>History of artificial intelligence: Key dates and names
    The idea of 'a machine that thinks' dates back to ancient Greece. But since the advent of electronic computing (and relative to some of the topics discussed in this article) important events and milestones in the evolution of artificial intelligence include the following:
    
    1950: Alan Turing publishes Computing Machinery and Intelligence. In the paper, Turing—famous for breaking the Nazi's ENIGMA code during WWII—proposes to answer the question 'can machines think?' and introduces the Turing Test to determine if a computer can demonstrate the same intelligence (or the results of the same intelligence) as a human. The value of the Turing test has been debated ever since.
    1956: John McCarthy coins the term 'artificial intelligence' at the first-ever AI conference at Dartmouth College. (McCarthy would go on to invent the Lisp language.) Later that year, Allen Newell, J.C. Shaw, and Herbert Simon create the Logic Theorist, the first-ever running AI software program.
    1967: Frank Rosenblatt builds the Mark 1 Perceptron, the first computer based on a neural network that 'learned' though trial and error. Just a year later, Marvin Minsky and Seymour Papert publish a book titled Perceptrons, which becomes both the landmark work on neural networks and, at least for a while, an argument against future neural network research projects.
    1980s: Neural networks which use a backpropagation algorithm to train itself become widely used in AI applications.
    1997: IBM's Deep Blue beats then world chess champion Garry Kasparov, in a chess match (and rematch).
    2011: IBM Watson beats champions Ken Jennings and Brad Rutter at Jeopardy!
    2015: Baidu's Minwa supercomputer uses a special kind of deep neural network called a convolutional neural network to identify and categorize images with a higher rate of accuracy than the average human.
    2016: DeepMind's AlphaGo program, powered by a deep neural network, beats Lee Sodol, the world champion Go player, in a five-game match. The victory is significant given the huge number of possible moves as the game progresses (over 14.5 trillion after just four moves!). Later, Google purchased DeepMind for a reported $400 million.</h3>
</body>
</html>
